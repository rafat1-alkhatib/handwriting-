# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IBxmJl97CuxSEe9hpM3D1dosVsHBUXpT
"""

# from google.colab import drive
# drive.mount('/content/drive')

import tensorflow as tf     ##tensorflow-gpu
import cv2                  ##opencv-python
import os
import matplotlib.pyplot as plt  ## matplotlib
import numpy as np
from google.colab.patches import cv2_imshow

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
    print('GPU device not found. Make sure you have enabled the GPU runtime.')
else:
    print('GPU device found:', device_name)

def resize_with_padding(image, target_size, padding_color=(0, 0, 0)):
    try:
        height, width = image.shape[:2]
        target_height, target_width = target_size
        aspect_ratio = width / height
        target_aspect_ratio = target_width / target_height
        if target_aspect_ratio > aspect_ratio:
            new_width = int(target_height * aspect_ratio)
            new_height = target_height
            pad_left = (target_width - new_width) // 2
            pad_right = target_width - new_width - pad_left
            pad_top = 0
            pad_bottom = 0
        else:
            new_width = target_width
            new_height = int(target_width / aspect_ratio)
            pad_left = 0
            pad_right = 0
            pad_top = (target_height - new_height) // 2
            pad_bottom = target_height - new_height - pad_top
        resized_image = cv2.resize(image, (new_width, new_height))
        padded_image = np.full((target_height, target_width, 3), padding_color, dtype=np.uint8)
        padded_image[pad_top:pad_top+new_height, pad_left:pad_left+new_width] = resized_image
        return padded_image
    except Exception as e:
        print("An error occurred during image resizing:", str(e))
        return None

train_data= r'/content/drive/MyDrive/2 ba'
Classes = ['2.1' ,'2.2','2.3','2.4','2.5' ]
print(".........1_Step...............")
for category in Classes :
    path=os.path.join(train_data,category)
    for img in os.listdir(path):
       img_array=cv2.imread(os.path.join(path,img))
       backtorgb = cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)
       plt.imshow(cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB))
       plt.show()
       break
    break
print(".........2_Step...............")
print("Resize_image")
img_size= 224 # ImageNet=>224*224
new_array = resize_with_padding(img_array, (224, 224), padding_color=(255, 255, 255))  # Resize the image with padding and set padding color to white
cv2_imshow(new_array)
cv2.waitKey(0)
cv2.destroyAllWindows()

print("new_array",new_array.shape)
print("old_array")
img_array.shape

print(".........3_Step...............")
print("reading all the images and converting them to arrays")
import os
import cv2
import random
import numpy as np
training_Data = []  # data
labels = []  # labels
def create_training_Data():
    for category in Classes:
        path = os.path.join(train_data, category)
        class_num = Classes.index(category)  # label
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img))
                new_array = cv2.resize(img_array, (img_size, img_size))
                training_Data.append(new_array)
                labels.append(class_num)
            except Exception as e:
                pass

print("training_Data")
create_training_Data()
print(len(training_Data))
temp = np.array(training_Data)
print(temp.shape)
combined_data = list(zip(training_Data, labels))
random.shuffle(combined_data)
X = []  # data/feature
Y = []  # label
for features, label in combined_data:
    X.append(features)
    Y.append(label)
print("converting it to 4 dimensions")
X = np.array(X).reshape(-1, img_size, img_size, 3)  # converting it to 4 dimensions
print(X.shape)

print(".........4_Step...............")
print("normalize the data")
X=X/255.0;  #we ara normalizrd it
Y=np.array(Y)
Y.shape
X.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.05, random_state=12)
print(X_train.shape)

import numpy as np
from tensorflow.keras.utils import to_categorical

# Assuming your training labels are stored in a list or array called 'train_labels'
train_labels = ['ba_iso','ba_first','ba_mid','ba_end' , 'error state']
# # Convert the labels to numerical format

label_mapping = {'ba_iso':0,'ba_first':1,'ba_mid':2,'ba_end':3 , 'error state':4 }

train_labels = [label_mapping[label] for label in train_labels]

# Convert the numerical labels to one-hot encoding
num_classes = len(label_mapping)
train_labels = to_categorical(train_labels, num_classes=num_classes)

# The train_labels variable is now ready to be used in model training
train_labels = np.repeat(train_labels, repeats=(len(X_train) // len(train_labels)), axis=0)
train_labels = np.concatenate((train_labels, train_labels[:len(X_train) % len(train_labels)]), axis=0)

import tensorflow as tf
from tensorflow.keras.applications import  EfficientNetB1
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D , Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

num_classes = 5
# Load the MobileNet model without the top classification layer
model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the initial layers of the base model
for layer in model.layers[:100]:
    layer.trainable = True

# Add your custom layers for classification
x = model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
#x = Dropout(0.5)(x)
predictions = Dense(num_classes, activation='softmax')(x)

# Create the final model
model = Model(inputs=model.input, outputs=predictions)

# Data augmentation
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.1
)
train_generator = train_datagen.flow(X_train, train_labels, batch_size=32)

# Compile the model with a lower learning rate
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)

model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

lr_scheduler = ReduceLROnPlateau(factor=0.1, patience=3)

early_stopping = EarlyStopping(patience=5, restore_best_weights=True)

# Train the model with fine-tuning

train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

# Train the model
y_train_categorical = to_categorical(y_train, num_classes=5)

# Train the model with fine-tuning
history=model.fit(X_train,y_train_categorical, epochs=65,  callbacks=[lr_scheduler, early_stopping])

model.save('ba_state_error.h5')
model=tf.keras.models.load_model('ba_state_error.h5')

y_test_categorical = to_categorical(y_test, num_classes=5)

loss, accuracy=model.evaluate(X_test,y_test_categorical)
print("accuracy=",accuracy)

SIZE=256
n_model=tf.keras.models.load_model('/content/ba_state_error.h5')

# Commented out IPython magic to ensure Python compatibility.
print(".........8_Step...............")
print("list all data in history")
import matplotlib.pyplot as plt
from tensorflow.python.lib.io import file_io
# %matplotlib inline
import keras
from keras import backend as K
from keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.utils import plot_model
from sklearn.metrics import *
import skimage
from skimage.transform import rescale, resize
import pydot
print(".........9_Step...............")
# list all data in history",
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
#plt.plot(history.history['val_acc'])
plt.title('new_model resnet accuracy')
plt.ylabel('accuracy(%)')
plt.xlabel('epoch')
plt.legend(['train', 'dev'], loc='upper left')
plt.show()
 #summarize history for loss
plt.plot(history.history['loss'])
#plt.plot(history.history['val_loss'])
plt.title('new_model loss(%)')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'dev'], loc='upper left')
plt.show()

import tensorflow as tf
from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
# Load and preprocess the image
img_path = '/content/ba.png'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = preprocess_input(x)
x = tf.expand_dims(x, axis=0)

# Perform image prediction
new_x = resize_with_padding(x, (256, 256), padding_color=(255, 255, 255))  # Resize the image with padding and set padding color to white
new_x = preprocess_input(new_x)
new_x = tf.expand_dims(x, axis=0)
preds = model.predict(x)
print(preds)

print(".........10_Step...............")
print(".........Test dataset ...............")
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow.python.lib.io import file_io

import keras

from tensorflow.keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix
from seaborn import heatmap

charr = {0:'2.1', 1:'2.2', 2:'2.3',3:'2.4',4:'2.5'}
y_pred = model.predict(X_test).argmax(axis=1)
y_true = y_test

cmat_df_test=pd.DataFrame(
  confusion_matrix(y_true, y_pred, normalize='true').round(2),
  index=charr.values(),
  columns=charr.values()
  )
plt.figure(figsize=(5,5))
heatmap(cmat_df_test,annot=True,cmap=plt.cm.Blues)
plt.tight_layout()
plt.title('Confusion Matrix on Private Test Set')
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
print(" Finding Accuracy, precision and recall")
# Finding precision and recall
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy   :", accuracy)
precision = precision_score(y_test, y_pred,average="weighted")
print("Precision :", precision)
recall = recall_score(y_test, y_pred,average="weighted")
print("Recall    :", recall)
F1_score = f1_score(y_test, y_pred,average="weighted")
print("F1-score  :", F1_score)

print(".........12_Step...............")
from sklearn.preprocessing import LabelEncoder
#Check results on a few select images
n=np.random.randint(0, X_test.shape[0])
img = X_test[n]
plt.imshow(img)
input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)
input_img = np.reshape(input_img, (224, 224, 3))
input_img = np.expand_dims(input_img, axis=0)
input_img_feature=model.predict(input_img)
input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)
prediction = model.predict(input_img)[0]
le = LabelEncoder()
# prediction = le.inverse_transform([prediction])  #Reverse the label encoder to original name
print("The prediction for this image is: ", prediction)
print("The actual label for this image is: ", y_test[n])

from sklearn.preprocessing import LabelEncoder
import cv2
# Provide the file path of the image
img_path = '/content/asd.png'

# Read the image using OpenCV
img = cv2.imread(img_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Display the image
plt.imshow(img)
plt.show()

# Preprocess the image for prediction
input_img = cv2.resize(img, (224, 224))  # Resize the image to match the input size of the model
input_img = np.expand_dims(input_img, axis=0)  # Expand dims so the input is (num images, x, y, c)
input_img = input_img / 255.0  # Normalize the image pixels to the range [0, 1]

# Make the prediction
input_img_feature = model.predict(input_img)
input_img_features = input_img_feature.reshape(input_img_feature.shape[0], -1)
prediction = model.predict(input_img)[0]

# Fit the LabelEncoder with training labels
le = LabelEncoder()
le.fit(y_train)

# Reverse the label encoding to get the original class name
prediction = le.inverse_transform([np.argmax(prediction)])[0]
print("The prediction for this image is:", prediction)

